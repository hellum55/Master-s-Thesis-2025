{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdd6327b",
   "metadata": {},
   "source": [
    "Indlæs pakker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d1d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indlæs nødvendige biblioteker\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "#Data augmentation\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision.transforms import RandAugment\n",
    "\n",
    "#Split data\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#ResNet-18:\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "#Træning og validation\n",
    "from typing import Tuple\n",
    "from typing import Dict, List\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#Plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Grad-cam\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91719960",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    NUM_DEVICES = torch.cuda.device_count()\n",
    "    NUM_WORKERS = os.cpu_count()\n",
    "    NUM_CLASSES = 30\n",
    "    EPOCHS = 30\n",
    "    BATCH_SIZE = (\n",
    "        256 if torch.cuda.device_count() < 2 \n",
    "        else (256 * torch.cuda.device_count())\n",
    "    )\n",
    "    TEST_SIZE = 0.15\n",
    "    LR = 0.001\n",
    "    LR_STEP_SIZE = 10\n",
    "    LR_GAMMA = 0.1\n",
    "    APPLY_SHUFFLE = True\n",
    "    SEED = 768\n",
    "    HEIGHT = 224\n",
    "    WIDTH = 224\n",
    "    CHANNELS = 3\n",
    "    IMAGE_SIZE = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a388da1",
   "metadata": {},
   "source": [
    "Indlæs datasæt ved hjælp fra csv fil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9170a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row[\"file_name\"]).convert(\"RGB\")\n",
    "        label = torch.tensor(row[\"label_idx\"]).long()\n",
    "        image_path = row[\"file_name\"]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, image_path\n",
    "\n",
    "def load_dataset(csv_path: str, image_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads the filtered dataframe, appends full image paths, encodes labels,\n",
    "    and checks for missing files.\n",
    "\n",
    "    Returns:\n",
    "        df: Pandas DataFrame with encoded labels and image paths\n",
    "        idx_to_label: Dictionary mapping encoded label indices back to strings\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    df[\"file_name\"] = df[\"file_name\"].astype(str) + \".png\"\n",
    "    df[\"file_name\"] = df[\"file_name\"].apply(lambda x: os.path.join(image_dir, x))\n",
    "\n",
    "    missing = df[~df[\"file_name\"].apply(os.path.exists)]\n",
    "    if not missing.empty:\n",
    "        print(f\"[Warning] Missing images: {len(missing)}\")\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    df[\"label_idx\"] = le.fit_transform(df[\"label\"])\n",
    "\n",
    "    idx_to_label = dict(enumerate(le.classes_))\n",
    "    return df, idx_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ba388",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"\"\n",
    "image_dir = \"\"\n",
    "df, idx_to_label = load_dataset(csv_path, image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc0dd4",
   "metadata": {},
   "source": [
    "Udregn gennemsnit og standard afvigelse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d122673",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_set = datasets.CIFAR10(\n",
    "    root=\"\", transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "def get_mean_std(loader):\n",
    "    # var[X] = E[X**2] - E[X]**2\n",
    "    channels_sum, channels_sqrd_sum, num_batches = 0, 0, 0\n",
    "\n",
    "    for data, _ in tqdm(loader):\n",
    "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        channels_sqrd_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "\n",
    "    mean = channels_sum / num_batches\n",
    "    std = (channels_sqrd_sum / num_batches - mean**2) ** 0.5\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "mean, std = get_mean_std(train_loader)\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfdd546",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee149e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CannyEdgeTransform:\n",
    "    def __init__(self, p=0.3, threshold1=100, threshold2=200):\n",
    "        self.p = p\n",
    "        self.threshold1 = threshold1\n",
    "        self.threshold2 = threshold2\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:\n",
    "            img_np = np.array(img)\n",
    "            gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "            edges = cv2.Canny(gray, self.threshold1, self.threshold2)\n",
    "            edges_rgb = np.stack([edges]*3, axis=-1)\n",
    "            img = Image.fromarray(edges_rgb)\n",
    "        return img\n",
    "\n",
    "\n",
    "def random_transforms():\n",
    "    \"\"\"\n",
    "    Returns train and val transforms with a custom random augmentation policy.\n",
    "    \"\"\"\n",
    "\n",
    "    train_transforms = T.Compose([\n",
    "        T.Resize((CFG.HEIGHT, CFG.WIDTH)),\n",
    "        RandAugment(num_ops=3, magnitude=12),\n",
    "        CannyEdgeTransform(p=0.3),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.4914, 0.4821, 0.4465], std=[0.2470, 0.2435, 0.2615]),\n",
    "    ])\n",
    "\n",
    "\n",
    "    val_transforms = T.Compose([\n",
    "        T.Resize((CFG.HEIGHT, CFG.WIDTH)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.4914, 0.4821, 0.4465], std=[0.2470, 0.2435, 0.2615]),\n",
    "    ])\n",
    "\n",
    "    return train_transforms, val_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f0c2c",
   "metadata": {},
   "source": [
    "Split data i træning, validering og test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c20dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(df, train_transforms, val_transforms):\n",
    "    \"\"\"\n",
    "    Returns train, validation, and test datasets and dataloaders.\n",
    "    \"\"\"\n",
    "\n",
    "    # First split: Train + Temp (val + test)\n",
    "    train_df, temp_df = train_test_split(\n",
    "        df,\n",
    "        test_size=CFG.TEST_SIZE,\n",
    "        stratify=df[\"label_idx\"],\n",
    "        random_state=CFG.SEED\n",
    "    )\n",
    "\n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df,\n",
    "        test_size=0.4,\n",
    "        stratify=temp_df[\"label_idx\"],\n",
    "        random_state=CFG.SEED\n",
    "    )\n",
    "\n",
    "    train_dataset = ImageDataset(train_df, transform=train_transforms)\n",
    "    val_dataset = ImageDataset(val_df, transform=val_transforms)\n",
    "    test_dataset = ImageDataset(test_df, transform=val_transforms)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.BATCH_SIZE,\n",
    "        shuffle=CFG.APPLY_SHUFFLE,\n",
    "        num_workers=CFG.NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CFG.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=CFG.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef42448",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms, val_transforms = random_transforms()\n",
    "\n",
    "train_dataset, val_dataset, test_dataset, train_loader, val_loader, test_loader = get_dataloaders(\n",
    "    df, train_transforms, val_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f6e90d",
   "metadata": {},
   "source": [
    "ResNet-18 - lag 2 og 3 bliver 'unfrozen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea6561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(device: torch.device, num_classes: int = CFG.NUM_CLASSES) -> nn.Module:\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "    weights = ResNet18_Weights.DEFAULT\n",
    "    model = torchvision.models.resnet18(weights=weights).to(device)\n",
    "\n",
    "    # Freeze all layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    unfreeze_layers = [model.layer2, model.layer3]\n",
    "    for layer in unfreeze_layers:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(num_ftrs, 256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(256, num_classes),\n",
    "    ).to(device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577553c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = build_model(device=CFG.DEVICE)\n",
    "\n",
    "# View model summary\n",
    "summary(\n",
    "    model=cnn, \n",
    "    input_size=(CFG.BATCH_SIZE, CFG.CHANNELS, CFG.WIDTH, CFG.HEIGHT),\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b8f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Function\n",
    "loss_fn = nn.CrossEntropyLoss(\n",
    "    label_smoothing=0.1\n",
    ")\n",
    "\n",
    " #Define Optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    cnn.parameters(),\n",
    "    lr=CFG.LR)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=CFG.LR_STEP_SIZE, gamma=CFG.LR_GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec42a1",
   "metadata": {},
   "source": [
    "Definer træningsscript for hver epoch. Loss, Accuracy og top-3 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa17b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_epoch(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Executes a single training epoch and returns average loss, top-1 and top-5 accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    train_loss, top1_acc, top3_acc = 0.0, 0.0, 0.0\n",
    "\n",
    "    for X, y, _ in tqdm(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        top1 = torch.argmax(y_pred, dim=1)\n",
    "        top1_acc += (top1 == y).sum().item() / y.size(0)\n",
    "\n",
    "        top3_preds = torch.topk(y_pred, k=3, dim=1).indices\n",
    "        match_top3 = top3_preds.eq(y.view(-1, 1))  # shape: [batch, 5]\n",
    "        top3_acc += match_top3.any(dim=1).float().sum().item() / y.size(0)\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss /= num_batches\n",
    "    top1_acc /= num_batches\n",
    "    top3_acc /= num_batches\n",
    "\n",
    "    return train_loss, top1_acc, top3_acc\n",
    "\n",
    "def evaluate(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Evaluates model performance on a validation/test set.\n",
    "\n",
    "    Returns:\n",
    "        avg_loss, top1_accuracy, top3_accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss, top1_acc, top3_acc = 0.0, 0.0, 0.0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y, _ in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            top1 = torch.argmax(y_pred, dim=1)\n",
    "            top1_acc += (top1 == y).sum().item() / y.size(0)\n",
    "\n",
    "\n",
    "            top3_preds = torch.topk(y_pred, k=3, dim=1).indices\n",
    "            match_top3 = top3_preds.eq(y.view(-1, 1))\n",
    "            top3_acc += match_top3.any(dim=1).float().sum().item() / y.size(0)\n",
    "\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    eval_loss /= num_batches\n",
    "    top1_acc /= num_batches\n",
    "    top3_acc /= num_batches\n",
    "\n",
    "    return eval_loss, top1_acc, top3_acc\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    eval_dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    epochs: int,\n",
    "    device: torch.device,\n",
    "    writer: SummaryWriter,\n",
    "    save_path=\"\",\n",
    "    scheduler: torch.optim.lr_scheduler._LRScheduler = None\n",
    ") -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Trains and evaluates a model over multiple epochs and logs top-1 and top-3 accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    session = {\n",
    "        'loss': [],\n",
    "        'accuracy': [],\n",
    "        'top3_accuracy': [],\n",
    "        'eval_loss': [],\n",
    "        'eval_accuracy': [],\n",
    "        'eval_top3_accuracy': []\n",
    "    }\n",
    "\n",
    "    best_eval_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "\n",
    "        # Training\n",
    "        train_loss, train_top1, train_top3 = execute_epoch(\n",
    "            model, train_dataloader, optimizer, loss_fn, device\n",
    "        )\n",
    "\n",
    "        # Evaluation\n",
    "        eval_loss, eval_top1, eval_top3 = evaluate(\n",
    "            model, eval_dataloader, loss_fn, device\n",
    "        )\n",
    "\n",
    "        # ✅ Save best model based on validation loss\n",
    "        if eval_loss < best_eval_loss:\n",
    "            best_eval_loss = eval_loss\n",
    "            torch.save(model.state_dict(), os.path.join(save_path, \"best_model.pth\"))\n",
    "            print(f\"✅ Best model saved at epoch {epoch + 1} with eval_loss = {best_eval_loss:.4f}\")\n",
    "\n",
    "\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "        print(f\"Learning rate for epoch {epoch+1}: {current_lr:.6f}\")\n",
    "\n",
    "        # Log metrics to TensorBoard ✅\n",
    "        writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/Val\", eval_loss, epoch)\n",
    "        writer.add_scalar(\"Accuracy/Train_top1\", train_top1, epoch)\n",
    "        writer.add_scalar(\"Accuracy/Val_top1\", eval_top1, epoch)\n",
    "        writer.add_scalar(\"Accuracy/Train_top3\", train_top3, epoch)\n",
    "        writer.add_scalar(\"Accuracy/Val_top3\", eval_top3, epoch)\n",
    "\n",
    "        # Log current LR\n",
    "        if scheduler is not None:\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            writer.add_scalar(\"Learning_Rate\", current_lr, epoch)\n",
    "            scheduler.step()\n",
    "\n",
    "        # Print logs\n",
    "        print(\n",
    "            f'loss: {train_loss:.4f} - top1: {train_top1:.4f} - top3: {train_top3:.4f} '\n",
    "            f'- eval_loss: {eval_loss:.4f} - eval_top1: {eval_top1:.4f} - eval_top3: {eval_top3:.4f}'\n",
    "        )\n",
    "\n",
    "        # Save to session log\n",
    "        session['loss'].append(train_loss)\n",
    "        session['accuracy'].append(train_top1)\n",
    "        session['top3_accuracy'].append(train_top3)\n",
    "        session['eval_loss'].append(eval_loss)\n",
    "        session['eval_accuracy'].append(eval_top1)\n",
    "        session['eval_top3_accuracy'].append(eval_top3)\n",
    "\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=\"runs/exp2_final\")\n",
    "\n",
    "session = train(\n",
    "    model=cnn,\n",
    "    train_dataloader=train_loader,\n",
    "    eval_dataloader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=CFG.EPOCHS,\n",
    "    device=CFG.DEVICE,\n",
    "    writer=writer,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462c5146",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_history_df = pd.DataFrame(session)\n",
    "session_history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef4f4b2",
   "metadata": {},
   "source": [
    "Træning og valideringskurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e742ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(history):\n",
    "    \n",
    "    loss = np.array(history['loss'])\n",
    "    val_loss = np.array(history['eval_loss'])\n",
    "\n",
    "    accuracy = np.array(history['accuracy'])\n",
    "    val_accuracy = np.array(history['eval_accuracy'])\n",
    "\n",
    "    epochs = range(len(history['loss']))\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "    # Plot loss\n",
    "    ax1.plot(epochs, loss, label='training_loss', marker='o')\n",
    "    ax1.plot(epochs, val_loss, label='eval_loss', marker='o')\n",
    "    \n",
    "    ax1.fill_between(epochs, loss, val_loss, where=(loss > val_loss), color='C0', alpha=0.3, interpolate=True)\n",
    "    ax1.fill_between(epochs, loss, val_loss, where=(loss < val_loss), color='C1', alpha=0.3, interpolate=True)\n",
    "\n",
    "    ax1.set_title('Loss (Lower Means Better)', fontsize=16)\n",
    "    ax1.set_xlabel('Epochs', fontsize=12)\n",
    "    ax1.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    ax2.plot(epochs, accuracy, label='training_accuracy', marker='o')\n",
    "    ax2.plot(epochs, val_accuracy, label='eval_accuracy', marker='o')\n",
    "    \n",
    "    ax2.fill_between(epochs, accuracy, val_accuracy, where=(accuracy > val_accuracy), color='C0', alpha=0.3, interpolate=True)\n",
    "    ax2.fill_between(epochs, accuracy, val_accuracy, where=(accuracy < val_accuracy), color='C1', alpha=0.3, interpolate=True)\n",
    "\n",
    "    ax2.set_title('Accuracy (Higher Means Better)', fontsize=16)\n",
    "    ax2.set_xlabel('Epochs', fontsize=12)\n",
    "    ax2.legend();\n",
    "    \n",
    "    sns.despine();\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aee6833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot EfficientNet session training history \n",
    "plot_training_curves(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ed3b8",
   "metadata": {},
   "source": [
    "Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a06716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader=val_loader, device=CFG.DEVICE):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for images, labels, paths in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_paths.extend(paths)\n",
    "\n",
    "    return np.array(all_labels), np.array(all_preds), np.array(all_probs), all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab645534",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, y_probs, file_paths = get_predictions(cnn, val_loader, CFG.DEVICE)\n",
    "\n",
    "# Classification Report\n",
    "print(\"📋 Classification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=list(idx_to_label.values()), labels=list(idx_to_label.keys())))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=idx_to_label.values(), yticklabels=idx_to_label.values(), cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e74ca",
   "metadata": {},
   "source": [
    "Hvilke billeder gætter modellen meget forkert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b08e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def print_confidently_wrong(y_true, y_pred, y_probs, file_paths, idx_to_label, top_n=10):\n",
    "    \"\"\"\n",
    "    Prints the top N confidently wrong predictions based on prediction probability.\n",
    "    \"\"\"\n",
    "\n",
    "    wrong_idx = np.where(y_pred != y_true)[0]\n",
    "\n",
    "    if len(wrong_idx) == 0:\n",
    "        print(\"✅ No misclassifications found.\")\n",
    "        return\n",
    "\n",
    "    confidences = [y_probs[i][y_pred[i]] for i in wrong_idx]\n",
    "\n",
    "    sorted_indices = np.argsort(confidences)[-top_n:][::-1]\n",
    "    top_wrong_idx = [wrong_idx[i] for i in sorted_indices]\n",
    "\n",
    "    print(f\"\\n🔍 Top {len(top_wrong_idx)} confident misclassifications:\\n\")\n",
    "\n",
    "    for i in top_wrong_idx:\n",
    "        true_label = idx_to_label[y_true[i]]\n",
    "        pred_label = idx_to_label[y_pred[i]]\n",
    "        confidence = y_probs[i][y_pred[i]]\n",
    "        image_path = file_paths[i]\n",
    "        print(f\"🖼️ {os.path.basename(image_path)} | ❌ Pred: {pred_label} ({confidence:.2f}) | ✅ True: {true_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ebcdc",
   "metadata": {},
   "source": [
    "Specifikke typer som bliver gættet forkert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf2c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_specific_misclassifications(y_true, y_pred, file_paths, idx_to_label, target_true=\"MEL1\", target_pred=\"MEL2\", max_images=12):\n",
    "    \"\"\"\n",
    "    Displays images where the predicted label is 'target_pred' but the true label is 'target_true'.\n",
    "\n",
    "    Args:\n",
    "        y_true: array of ground truth label indices\n",
    "        y_pred: array of predicted label indices\n",
    "        file_paths: list of image file paths\n",
    "        idx_to_label: dictionary mapping label indices to label strings\n",
    "        target_true: class name that should be true\n",
    "        target_pred: class name that was wrongly predicted\n",
    "        max_images: maximum number of images to display\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert labels to class names\n",
    "    true_labels = [idx_to_label[i] for i in y_true]\n",
    "    pred_labels = [idx_to_label[i] for i in y_pred]\n",
    "\n",
    "    # Filter indices\n",
    "    match_indices = [\n",
    "        i for i, (true, pred) in enumerate(zip(true_labels, pred_labels))\n",
    "        if true == target_true and pred == target_pred\n",
    "    ]\n",
    "\n",
    "    if not match_indices:\n",
    "        print(f\"No misclassifications found where predicted = {target_pred} but true = {target_true}.\")\n",
    "        return\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, min(len(match_indices), max_images), figsize=(15, 5))\n",
    "    if len(match_indices) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, idx in zip(axes, match_indices[:max_images]):\n",
    "        img = Image.open(file_paths[idx])\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"Pred: {target_pred}\\nTrue: {target_true}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f39aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_specific_misclassifications(\n",
    "    y_true=y_true,\n",
    "    y_pred=y_pred,\n",
    "    file_paths=file_paths,\n",
    "    idx_to_label=idx_to_label,\n",
    "    target_true=\"BC\",\n",
    "    target_pred=\"BC K.M.skab\",\n",
    "    max_images=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351b312c",
   "metadata": {},
   "source": [
    "GRAD-Cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45fbf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Load model -----\n",
    "model = build_model(device=\"cuda\", num_classes=30)\n",
    "model.load_state_dict(torch.load(\"\"))\n",
    "model.eval()\n",
    "\n",
    "target_layer = model.layer4\n",
    "\n",
    "gradients = []\n",
    "\n",
    "def save_gradient(module, grad_input, grad_output):\n",
    "    gradients.append(grad_output[0])\n",
    "\n",
    "target_layer.register_backward_hook(save_gradient)\n",
    "\n",
    "def preprocess(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4821, 0.4465], std=[0.2470, 0.2435, 0.2615])\n",
    "    ])\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    return transform(img).unsqueeze(0), img\n",
    "\n",
    "# ----- Grad-CAM logic -----\n",
    "def generate_cam(model, image_tensor, class_idx):\n",
    "    activations = []\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        activations.append(output)\n",
    "\n",
    "    hook = target_layer.register_forward_hook(forward_hook)\n",
    "\n",
    "    output = model(image_tensor)\n",
    "    pred_class = output.argmax(dim=1).item() if class_idx is None else class_idx\n",
    "\n",
    "    model.zero_grad()\n",
    "    class_score = output[0, pred_class]\n",
    "    class_score.backward()\n",
    "\n",
    "    act = activations[0].squeeze(0).detach().cpu().numpy()\n",
    "    grad = gradients[0].squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "    weights = np.mean(grad, axis=(1, 2))\n",
    "    cam = np.zeros(act.shape[1:], dtype=np.float32)\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * act[i]\n",
    "\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cv2.resize(cam, (224, 224))\n",
    "    cam -= np.min(cam)\n",
    "    cam /= (np.max(cam) + 1e-8)\n",
    "\n",
    "    hook.remove()\n",
    "    return cam\n",
    "\n",
    "# ----- Plot result -----\n",
    "def show_cam_on_image(original_img, cam):\n",
    "    img = np.array(original_img.resize((224, 224))) / 255.0\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "    heatmap = heatmap[..., ::-1] / 255.0\n",
    "    superimposed_img = 0.5 * heatmap + 0.5 * img\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Grad-CAM\")\n",
    "    plt.show()\n",
    "\n",
    "# ----- Run -----\n",
    "image_tensor, original_img = preprocess(\"\")\n",
    "image_tensor = image_tensor.to(\"cuda\")\n",
    "cam = generate_cam(model, image_tensor, class_idx=None)\n",
    "show_cam_on_image(original_img, cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adb3b8c",
   "metadata": {},
   "source": [
    "Predictions på testsæt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds, all_labels, all_paths = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, paths in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(torch.softmax(outputs, dim=1), dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_paths.extend(paths)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"file_name\": all_paths,\n",
    "    \"true_label\": all_labels,\n",
    "    \"pred_label\": all_preds\n",
    "})\n",
    "results[\"true_label_name\"] = results[\"true_label\"].map(idx_to_label)\n",
    "results[\"pred_label_name\"] = results[\"pred_label\"].map(idx_to_label)\n",
    "\n",
    "results.to_csv(\"test_predictions.csv\", index=False)\n",
    "print(\"✅ Predictions saved to test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eb6b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (results[\"true_label\"] == results[\"pred_label\"]).mean()\n",
    "print(f\"Test set accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
